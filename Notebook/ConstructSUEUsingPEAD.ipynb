{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-11T22:17:14.830695Z",
     "start_time": "2024-10-11T22:17:13.490915Z"
    }
   },
   "source": [
    "#####################################\n",
    "# Post Earnings Announcement Drift  #\n",
    "# Qingyi (Freda) Song Drechsler     #\n",
    "# Date: June 2019                   #\n",
    "# Update: Jan 2021                  #\n",
    "#####################################\n",
    "\n",
    "# Update Note: this version uses CRSP data to extract S&P500 Index constituents,\n",
    "# as comp.idxcst_hist data is no longer available on WRDS\n",
    "# Also updated various .loc usage that has been deprecated by Python.\n",
    "# Source: https://www.fredasongdrechsler.com/data-crunching/pead\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrds\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import *\n",
    "import datetime\n",
    "\n",
    "from Constants import Constants as const\n",
    "\n",
    "# set sample date range\n",
    "begdate = '01/01/2007'\n",
    "enddate = '12/31/2016'\n",
    "\n",
    "# set CRSP date range a bit wider to guarantee collecting all information\n",
    "crsp_begdate = '01/01/2006'\n",
    "crsp_enddate = '12/31/2017'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:17:29.658049Z",
     "start_time": "2024-10-11T22:17:23.360037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Connect to WRDS\n",
    "conn = wrds.Connection(wrds_username='aheitz')"
   ],
   "id": "b8d85a9989d1293d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:17:30.945970Z",
     "start_time": "2024-10-11T22:17:30.927787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#################################\n",
    "# Step 0: Read in ICLINK output #\n",
    "#################################\n",
    "\n",
    "# iclink.pkl is the output from the python program iclink\n",
    "# it contains the linking between crsp and ibes\n",
    "iclink = pd.read_pickle(os.path.join(const.TEMP_PATH, '20241011_iclink.pkl'))"
   ],
   "id": "b120bec00a0745bc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:25:38.626628Z",
     "start_time": "2024-10-11T22:24:56.435963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##################################\n",
    "# Step 1. All CRSP firm Universe #\n",
    "##################################\n",
    "\n",
    "# All companies\n",
    "# Old version of the code uses comp.idxcst_his\n",
    "\n",
    "# New code uses crsp.\n",
    "# Linking Compustat GVKEY and IBES Tickers using ICLINK               \n",
    "# For unmatched GVKEYs, use header IBTIC link in Compustat Security file \n",
    "\n",
    "\n",
    "stock_list = conn.raw_sql(f\"\"\"\n",
    "                        select permno, securitybegdt as start, securityenddt as ending\n",
    "                        from crsp.wrds_msfv2_query as a;\n",
    "                        \"\"\", date_cols=['securitybegdt', 'securityenddt'])\n"
   ],
   "id": "950937f7b817b689",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:27:46.602020Z",
     "start_time": "2024-10-11T22:27:46.572584Z"
    }
   },
   "cell_type": "code",
   "source": "stock_list.drop_duplicates(inplace=True)",
   "id": "1c371b206e5de838",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:28:10.222363Z",
     "start_time": "2024-10-11T22:28:05.372038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CCM data\n",
    "_ccm = conn.raw_sql(\"\"\" select gvkey, lpermco as permco, lpermno as permno, \n",
    "                        linkdt, linkenddt \n",
    "                        from crsp.ccmxpf_linktable \n",
    "                        where usedflag=1 \n",
    "                        and linkprim in ('P', 'C')\"\"\", date_cols=['linkdt', 'linkenddt'])\n",
    "\n",
    "_ccm[['permco', 'permno']] = _ccm[['permco', 'permno']].astype(int)\n",
    "\n",
    "# Fill linkenddt missing value (.E in SAS dataset) with today's date\n",
    "_ccm['linkenddt'] = _ccm.linkenddt.fillna(datetime.date.today())\n",
    "\n",
    "_sec = conn.raw_sql(\"\"\" select ibtic, gvkey from comp.security \"\"\")\n",
    "\n",
    "\n",
    "# Start the sequence of left join\n",
    "gvkey = pd.merge(stock_list, _ccm, how='left', on=['permno'])\n",
    "gvkey = pd.merge(gvkey, _sec.loc[_sec.ibtic.notna()], how='left', on=['gvkey'])\n",
    "\n",
    "# high quality links from iclink\n",
    "# score = 0 or 1\n",
    "iclink_hq = iclink.loc[(iclink.score <=1)]\n",
    "\n",
    "gvkey = pd.merge(gvkey, iclink_hq, how='left', on=['permno'])\n",
    "\n",
    "# fill missing ticker with ibtic\n",
    "gvkey.ticker = np.where(gvkey.ticker.notnull(), gvkey.ticker, gvkey.ibtic)\n",
    "\n",
    "# Keep relevant columns and drop duplicates if there is any\n",
    "gvkey = gvkey[['gvkey', 'permco', 'permno', 'linkdt', 'linkenddt','ticker']]\n",
    "\n",
    "gvkey = gvkey.drop_duplicates()"
   ],
   "id": "de2ec898300c9dfa",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->max,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001B[0m, in \u001B[0;36mGroupBy._agg_py_fallback\u001B[1;34m(self, how, values, ndim, alt)\u001B[0m\n\u001B[0;32m   1941\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1942\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_grouper\u001B[38;5;241m.\u001B[39magg_series(ser, alt, preserve_dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1943\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001B[0m, in \u001B[0;36mBaseGrouper.agg_series\u001B[1;34m(self, obj, func, preserve_dtype)\u001B[0m\n\u001B[0;32m    862\u001B[0m     preserve_dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 864\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_series_pure_python(obj, func)\n\u001B[0;32m    866\u001B[0m npvalues \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mmaybe_convert_objects(result, try_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001B[0m, in \u001B[0;36mBaseGrouper._aggregate_series_pure_python\u001B[1;34m(self, obj, func)\u001B[0m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(splitter):\n\u001B[1;32m--> 885\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(group)\n\u001B[0;32m    886\u001B[0m     res \u001B[38;5;241m=\u001B[39m extract_result(res)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2810\u001B[0m, in \u001B[0;36mmax\u001B[1;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m   2696\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2697\u001B[0m \u001B[38;5;124;03mReturn the maximum of an array or maximum along an axis.\u001B[39;00m\n\u001B[0;32m   2698\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2808\u001B[0m \u001B[38;5;124;03m5\u001B[39;00m\n\u001B[0;32m   2809\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2810\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _wrapreduction(a, np\u001B[38;5;241m.\u001B[39mmaximum, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m, axis, \u001B[38;5;28;01mNone\u001B[39;00m, out,\n\u001B[0;32m   2811\u001B[0m                       keepdims\u001B[38;5;241m=\u001B[39mkeepdims, initial\u001B[38;5;241m=\u001B[39minitial, where\u001B[38;5;241m=\u001B[39mwhere)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001B[0m, in \u001B[0;36m_wrapreduction\u001B[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 86\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ufunc\u001B[38;5;241m.\u001B[39mreduce(obj, axis, dtype, out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6517\u001B[0m, in \u001B[0;36mSeries.max\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m   6509\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m   6510\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmax\u001B[39m(\n\u001B[0;32m   6511\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   6515\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   6516\u001B[0m ):\n\u001B[1;32m-> 6517\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m NDFrame\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;28mself\u001B[39m, axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12404\u001B[0m, in \u001B[0;36mNDFrame.max\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12397\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmax\u001B[39m(\n\u001B[0;32m  12398\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  12399\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  12402\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12403\u001B[0m ):\n\u001B[1;32m> 12404\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_function(\n\u001B[0;32m  12405\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m  12406\u001B[0m         nanops\u001B[38;5;241m.\u001B[39mnanmax,\n\u001B[0;32m  12407\u001B[0m         axis,\n\u001B[0;32m  12408\u001B[0m         skipna,\n\u001B[0;32m  12409\u001B[0m         numeric_only,\n\u001B[0;32m  12410\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12411\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12375\u001B[0m validate_bool_kwarg(skipna, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipna\u001B[39m\u001B[38;5;124m\"\u001B[39m, none_allowed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m> 12377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reduce(\n\u001B[0;32m  12378\u001B[0m     func, name\u001B[38;5;241m=\u001B[39mname, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only\n\u001B[0;32m  12379\u001B[0m )\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001B[0m, in \u001B[0;36mSeries._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m   6453\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   6454\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not allow \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwd_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumeric_only\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6455\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith non-numeric dtypes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6456\u001B[0m     )\n\u001B[1;32m-> 6457\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op(delegate, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[1;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[0;32m    402\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[1;32m--> 404\u001B[0m result \u001B[38;5;241m=\u001B[39m func(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, mask\u001B[38;5;241m=\u001B[39mmask, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1098\u001B[0m, in \u001B[0;36m_nanminmax.<locals>.reduction\u001B[1;34m(values, axis, skipna, mask)\u001B[0m\n\u001B[0;32m   1095\u001B[0m values, mask \u001B[38;5;241m=\u001B[39m _get_values(\n\u001B[0;32m   1096\u001B[0m     values, skipna, fill_value_typ\u001B[38;5;241m=\u001B[39mfill_value_typ, mask\u001B[38;5;241m=\u001B[39mmask\n\u001B[0;32m   1097\u001B[0m )\n\u001B[1;32m-> 1098\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(values, meth)(axis)\n\u001B[0;32m   1099\u001B[0m result \u001B[38;5;241m=\u001B[39m _maybe_null_out(result, axis, mask, values\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:41\u001B[0m, in \u001B[0;36m_amax\u001B[1;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_amax\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     40\u001B[0m           initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m umr_maximum(a, axis, \u001B[38;5;28;01mNone\u001B[39;00m, out, keepdims, initial, where)\n",
      "File \u001B[1;32mtimestamps.pyx:377\u001B[0m, in \u001B[0;36mpandas._libs.tslibs.timestamps._Timestamp.__richcmp__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Cannot compare Timestamp with datetime.date. Use ts == pd.Timestamp(date) or ts.date() == date instead.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 39\u001B[0m\n\u001B[0;32m     36\u001B[0m gvkey_mindt \u001B[38;5;241m=\u001B[39m gvkey\u001B[38;5;241m.\u001B[39mgroupby([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mticker\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpermno\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mlinkdt\u001B[38;5;241m.\u001B[39mmin()\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# max linkenddt for ticker and permno combination\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m gvkey_maxdt \u001B[38;5;241m=\u001B[39m gvkey\u001B[38;5;241m.\u001B[39mgroupby([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mticker\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpermno\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mlinkenddt\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# link date range \u001B[39;00m\n\u001B[0;32m     42\u001B[0m gvkey_dt \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(gvkey_mindt, gvkey_maxdt, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m, on\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mticker\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpermno\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:3330\u001B[0m, in \u001B[0;36mGroupBy.max\u001B[1;34m(self, numeric_only, min_count, engine, engine_kwargs)\u001B[0m\n\u001B[0;32m   3322\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_numba_agg_general(\n\u001B[0;32m   3323\u001B[0m         grouped_min_max,\n\u001B[0;32m   3324\u001B[0m         executor\u001B[38;5;241m.\u001B[39midentity_dtype_mapping,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3327\u001B[0m         is_max\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   3328\u001B[0m     )\n\u001B[0;32m   3329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3330\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_agg_general(\n\u001B[0;32m   3331\u001B[0m         numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only,\n\u001B[0;32m   3332\u001B[0m         min_count\u001B[38;5;241m=\u001B[39mmin_count,\n\u001B[0;32m   3333\u001B[0m         alias\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3334\u001B[0m         npfunc\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mmax,\n\u001B[0;32m   3335\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1906\u001B[0m, in \u001B[0;36mGroupBy._agg_general\u001B[1;34m(self, numeric_only, min_count, alias, npfunc, **kwargs)\u001B[0m\n\u001B[0;32m   1896\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m   1897\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_agg_general\u001B[39m(\n\u001B[0;32m   1898\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1904\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1905\u001B[0m ):\n\u001B[1;32m-> 1906\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cython_agg_general(\n\u001B[0;32m   1907\u001B[0m         how\u001B[38;5;241m=\u001B[39malias,\n\u001B[0;32m   1908\u001B[0m         alt\u001B[38;5;241m=\u001B[39mnpfunc,\n\u001B[0;32m   1909\u001B[0m         numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only,\n\u001B[0;32m   1910\u001B[0m         min_count\u001B[38;5;241m=\u001B[39mmin_count,\n\u001B[0;32m   1911\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1912\u001B[0m     )\n\u001B[0;32m   1913\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgroupby\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001B[0m, in \u001B[0;36mGroupBy._cython_agg_general\u001B[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001B[0m\n\u001B[0;32m   1995\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_agg_py_fallback(how, values, ndim\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mndim, alt\u001B[38;5;241m=\u001B[39malt)\n\u001B[0;32m   1996\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m-> 1998\u001B[0m new_mgr \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mgrouped_reduce(array_func)\n\u001B[0;32m   1999\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_agged_manager(new_mgr)\n\u001B[0;32m   2000\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m how \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midxmin\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midxmax\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:367\u001B[0m, in \u001B[0;36mSingleDataManager.grouped_reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgrouped_reduce\u001B[39m(\u001B[38;5;28mself\u001B[39m, func):\n\u001B[0;32m    366\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39marray\n\u001B[1;32m--> 367\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(arr)\n\u001B[0;32m    368\u001B[0m     index \u001B[38;5;241m=\u001B[39m default_index(\u001B[38;5;28mlen\u001B[39m(res))\n\u001B[0;32m    370\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_array(res, index)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001B[0m, in \u001B[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001B[1;34m(values)\u001B[0m\n\u001B[0;32m   1992\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m   1994\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m alt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1995\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_agg_py_fallback(how, values, ndim\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mndim, alt\u001B[38;5;241m=\u001B[39malt)\n\u001B[0;32m   1996\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001B[0m, in \u001B[0;36mGroupBy._agg_py_fallback\u001B[1;34m(self, how, values, ndim, alt)\u001B[0m\n\u001B[0;32m   1944\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124magg function failed [how->\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhow\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,dtype->\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mser\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1945\u001B[0m     \u001B[38;5;66;03m# preserve the kind of exception that raised\u001B[39;00m\n\u001B[1;32m-> 1946\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(err)(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ser\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m   1949\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m res_values\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: agg function failed [how->max,dtype->object]"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:32:38.548134Z",
     "start_time": "2024-10-11T22:32:38.496456Z"
    }
   },
   "cell_type": "code",
   "source": "gvkey.linkenddt.max()",
   "id": "f1adc82180e50878",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot compare Timestamp with datetime.date. Use ts == pd.Timestamp(date) or ts.date() == date instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m gvkey\u001B[38;5;241m.\u001B[39mlinkenddt\u001B[38;5;241m.\u001B[39mmax()\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6517\u001B[0m, in \u001B[0;36mSeries.max\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m   6509\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m   6510\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmax\u001B[39m(\n\u001B[0;32m   6511\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   6515\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   6516\u001B[0m ):\n\u001B[1;32m-> 6517\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m NDFrame\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;28mself\u001B[39m, axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12404\u001B[0m, in \u001B[0;36mNDFrame.max\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12397\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmax\u001B[39m(\n\u001B[0;32m  12398\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  12399\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  12402\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12403\u001B[0m ):\n\u001B[1;32m> 12404\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_function(\n\u001B[0;32m  12405\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m  12406\u001B[0m         nanops\u001B[38;5;241m.\u001B[39mnanmax,\n\u001B[0;32m  12407\u001B[0m         axis,\n\u001B[0;32m  12408\u001B[0m         skipna,\n\u001B[0;32m  12409\u001B[0m         numeric_only,\n\u001B[0;32m  12410\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12411\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12373\u001B[0m nv\u001B[38;5;241m.\u001B[39mvalidate_func(name, (), kwargs)\n\u001B[0;32m  12375\u001B[0m validate_bool_kwarg(skipna, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipna\u001B[39m\u001B[38;5;124m\"\u001B[39m, none_allowed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m> 12377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reduce(\n\u001B[0;32m  12378\u001B[0m     func, name\u001B[38;5;241m=\u001B[39mname, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only\n\u001B[0;32m  12379\u001B[0m )\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001B[0m, in \u001B[0;36mSeries._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m   6452\u001B[0m     \u001B[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001B[39;00m\n\u001B[0;32m   6453\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   6454\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not allow \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwd_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumeric_only\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6455\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith non-numeric dtypes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6456\u001B[0m     )\n\u001B[1;32m-> 6457\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op(delegate, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    145\u001B[0m         result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[1;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike \u001B[38;5;129;01mand\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    402\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[1;32m--> 404\u001B[0m result \u001B[38;5;241m=\u001B[39m func(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, mask\u001B[38;5;241m=\u001B[39mmask, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n\u001B[0;32m    407\u001B[0m     result \u001B[38;5;241m=\u001B[39m _wrap_results(result, orig_values\u001B[38;5;241m.\u001B[39mdtype, fill_value\u001B[38;5;241m=\u001B[39miNaT)\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1098\u001B[0m, in \u001B[0;36m_nanminmax.<locals>.reduction\u001B[1;34m(values, axis, skipna, mask)\u001B[0m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _na_for_min_count(values, axis)\n\u001B[0;32m   1095\u001B[0m values, mask \u001B[38;5;241m=\u001B[39m _get_values(\n\u001B[0;32m   1096\u001B[0m     values, skipna, fill_value_typ\u001B[38;5;241m=\u001B[39mfill_value_typ, mask\u001B[38;5;241m=\u001B[39mmask\n\u001B[0;32m   1097\u001B[0m )\n\u001B[1;32m-> 1098\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(values, meth)(axis)\n\u001B[0;32m   1099\u001B[0m result \u001B[38;5;241m=\u001B[39m _maybe_null_out(result, axis, mask, values\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:41\u001B[0m, in \u001B[0;36m_amax\u001B[1;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_amax\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     40\u001B[0m           initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m umr_maximum(a, axis, \u001B[38;5;28;01mNone\u001B[39;00m, out, keepdims, initial, where)\n",
      "File \u001B[1;32mtimestamps.pyx:377\u001B[0m, in \u001B[0;36mpandas._libs.tslibs.timestamps._Timestamp.__richcmp__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Cannot compare Timestamp with datetime.date. Use ts == pd.Timestamp(date) or ts.date() == date instead."
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:32:56.652077Z",
     "start_time": "2024-10-11T22:32:56.578495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gvkey['linkenddt'] = pd.to_datetime(gvkey['linkenddt'].fillna(datetime.date.today()))\n",
    "\n",
    "# date ranges from gvkey\n",
    "# min linkdt for ticker and permno combination\n",
    "gvkey_mindt = gvkey.groupby(['ticker','permno']).linkdt.min().reset_index()\n",
    "\n",
    "# max linkenddt for ticker and permno combination\n",
    "gvkey_maxdt = gvkey.groupby(['ticker','permno']).linkenddt.max().reset_index()\n",
    "\n",
    "# link date range \n",
    "gvkey_dt = pd.merge(gvkey_mindt, gvkey_maxdt, how='inner', on=['ticker','permno'])"
   ],
   "id": "b24690f841ec64ad",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:34:13.685811Z",
     "start_time": "2024-10-11T22:33:04.964835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#######################################\n",
    "# Step 2. Extract Estimates from IBES #\n",
    "#######################################\n",
    "\n",
    "# Extract estimates from IBES Unadjusted file and select    \n",
    "# the latest estimate for a firm within broker-analyst group\n",
    "# \"fpi in (6,7)\" selects quarterly forecast for the current \n",
    "# and the next fiscal quarter    \n",
    "\n",
    "ibes_temp = conn.raw_sql(f\"\"\"\n",
    "                        select ticker, estimator, analys, pdf, fpi, value, \n",
    "                        fpedats, revdats, revtims, anndats, anntims\n",
    "                        from ibes.detu_epsus \n",
    "                        where fpedats between '{begdate}' and '{enddate}'\n",
    "                        and (fpi='6' or fpi='7')\n",
    "                        \"\"\", date_cols = ['revdats', 'anndats', 'fpedats'])\n",
    "\n",
    "\n",
    "# merge to get date range linkdt and linkenddt to fulfill date requirement\n",
    "ibes_temp = pd.merge(ibes_temp, gvkey_dt, how='left', on=['ticker'])\n",
    "ibes_temp = ibes_temp.loc[(ibes_temp.linkdt<=ibes_temp.anndats) & (ibes_temp.anndats <= ibes_temp.linkenddt)]"
   ],
   "id": "9a7fb2bff96663f3",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:34:45.957529Z",
     "start_time": "2024-10-11T22:34:13.691823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count number of estimates reported on primary/diluted basis \n",
    "\n",
    "p_sub = ibes_temp[['ticker','fpedats','pdf']].loc[ibes_temp.pdf=='P']\n",
    "d_sub = ibes_temp[['ticker','fpedats','pdf']].loc[ibes_temp.pdf=='D']\n",
    "\n",
    "p_count = p_sub.groupby(['ticker','fpedats']).pdf.count().reset_index().rename(columns={'pdf':'p_count'})\n",
    "d_count = d_sub.groupby(['ticker','fpedats']).pdf.count().reset_index().rename(columns={'pdf':'d_count'})\n",
    "\n",
    "ibes = pd.merge(ibes_temp, d_count, how = 'left', on=['ticker', 'fpedats'])\n",
    "ibes = pd.merge(ibes, p_count, how='left', on =['ticker','fpedats'])\n",
    "ibes['d_count'] = ibes.d_count.fillna(0)\n",
    "ibes['p_count'] = ibes.p_count.fillna(0)\n",
    "\n",
    "# Determine whether most analysts report estimates on primary/diluted basis\n",
    "# following Livnat and Mendenhall (2006)                                   \n",
    "\n",
    "ibes['basis']=np.where(ibes.p_count>ibes.d_count, 'P', 'D')\n",
    "\n",
    "ibes = ibes.sort_values(by=['ticker','fpedats','estimator','analys','anndats', 'anntims', 'revdats', 'revtims'])\\\n",
    ".drop(['linkdt', 'linkenddt','p_count','d_count', 'pdf', 'fpi'], axis=1)\n",
    "\n",
    "# Keep the latest observation for a given analyst\n",
    "# Group by company fpedats estimator analys then pick the last record in the group\n",
    "\n",
    "ibes_1 = ibes.groupby(['ticker','fpedats','estimator','analys']).apply(lambda x: x.index[-1]).to_frame().reset_index()\n",
    "\n",
    "# reset index to the old dataframe index for join in the next step\n",
    "ibes_1=ibes_1.set_index(0)\n",
    "\n",
    "# Inner join with the last analyst record per group\n",
    "ibes = pd.merge(ibes, ibes_1[['analys']], left_index=True, right_index=True)\n",
    "\n",
    "# drop duplicate column\n",
    "ibes=ibes.drop(['analys_y'], axis=1).rename(columns={'analys_x': 'analys'})"
   ],
   "id": "1dffbca2cb27b7b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangy\\AppData\\Local\\Temp\\ipykernel_26396\\2941338626.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ibes_1 = ibes.groupby(['ticker','fpedats','estimator','analys']).apply(lambda x: x.index[-1]).to_frame().reset_index()\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:34:53.506795Z",
     "start_time": "2024-10-11T22:34:49.342278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#######################################\n",
    "# Step 3. Link Estimates with Actuals #\n",
    "#######################################\n",
    "\n",
    "# Link Unadjusted estimates with Unadjusted actuals and CRSP permnos  \n",
    "# Keep only the estimates issued within 90 days before the report date\n",
    "\n",
    "# Getting actual piece of data\n",
    "ibes_act = conn.raw_sql(f\"\"\"\n",
    "                        select ticker, anndats as repdats, value as act, pends as fpedats, pdicity\n",
    "                        from ibes.actu_epsus \n",
    "                        where pends between '{begdate}' and '{enddate}'\n",
    "                        and pdicity='QTR'\n",
    "                        \"\"\", date_cols = ['repdats', 'fpedats'])\n",
    "\n",
    "\n",
    "# Join with the estimate piece of the data\n",
    "\n",
    "ibes1 = pd.merge(ibes, ibes_act, how='left', on = ['ticker','fpedats'])\n",
    "ibes1['dgap'] = ibes1.repdats - ibes1.anndats\n",
    "\n",
    "ibes1['flag'] = np.where( (ibes1.dgap>=datetime.timedelta(days=0)) & (ibes1.dgap<=datetime.timedelta(days=90)) & (ibes1.repdats.notna()) & (ibes1.anndats.notna()), 1, 0)\n",
    "\n",
    "ibes1 = ibes1.loc[ibes1.flag==1].drop(['flag', 'dgap', 'pdicity'], axis=1)\n",
    "\n",
    "# Select all relevant combinations of Permnos and Date\n",
    "\n",
    "ibes1_dt1 = ibes1[['permno', 'anndats']].drop_duplicates()\n",
    "\n",
    "ibes1_dt2 = ibes1[['permno', 'repdats']].drop_duplicates().rename(columns={'repdats':'anndats'})\n",
    "\n",
    "ibes_anndats = pd.concat([ibes1_dt1, ibes1_dt2]).drop_duplicates()"
   ],
   "id": "174949d6208f42d7",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:36:31.110775Z",
     "start_time": "2024-10-11T22:36:29.845243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adjust all estimate and earnings announcement dates to the closest\n",
    "# preceding trading date in CRSP to ensure that adjustment factors won't\n",
    "# be missing after the merge  \n",
    "\n",
    "# unique anndats from ibes\n",
    "uniq_anndats = ibes_anndats[['anndats']].drop_duplicates()\n",
    "\n",
    "# unique trade dates from crsp.dsi\n",
    "crsp_dats = conn.raw_sql(\"\"\" \n",
    "                            select date \n",
    "                            from crsp.dsi \n",
    "                         \"\"\", date_cols=['date'])\n",
    "\n",
    "# Create up to 5 days prior dates relative to anndats\n",
    "\n",
    "for i in range(0, 5):\n",
    "    uniq_anndats[i] = uniq_anndats.anndats - datetime.timedelta(days=i)\n",
    "\n",
    "# reshape (transpose) the df for later join with crsp trading dates\n",
    "\n",
    "expand_anndats = uniq_anndats.set_index('anndats').stack().reset_index().\\\n",
    "rename(columns={'level_1':'prior', 0:'prior_date'})\n",
    "\n",
    "# merge with crsp trading dates\n",
    "tradedates = pd.merge(expand_anndats, crsp_dats, how='left', left_on=['prior_date'], right_on=['date'])\n",
    "\n",
    "# create the dgap (days gap) variable for min selection\n",
    "tradedates['dgap'] = tradedates.anndats-tradedates.date\n",
    "\n",
    "# choosing the row with the smallest dgap for a given anndats\n",
    "tradedates = tradedates.loc[tradedates.groupby('anndats')['dgap'].idxmin()]\n",
    "\n",
    "tradedates = tradedates[['anndats', 'date']]"
   ],
   "id": "4118bd41d3c9c3ef",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:38:36.753158Z",
     "start_time": "2024-10-11T22:36:41.110346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# merge the CRSP adjustment factors for all estimate and report dates\n",
    "\n",
    "# extract CRSP adjustment factors\n",
    "cfacshr = conn.raw_sql(f\"\"\"\n",
    "                        select permno, date, cfacshr\n",
    "                        from crsp.dsf\n",
    "                        where date between '{crsp_begdate}' and '{crsp_enddate}'\n",
    "                        \"\"\", date_cols = ['date'])\n",
    "\n",
    "ibes_anndats = pd.merge(ibes_anndats, tradedates, how='left', on = ['anndats'])\n",
    "\n",
    "ibes_anndats = pd.merge(ibes_anndats, cfacshr, how='left', on=['permno', 'date'])"
   ],
   "id": "a4dad650ad76c990",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:38:42.099802Z",
     "start_time": "2024-10-11T22:38:40.221015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#########################################\n",
    "# Step 4. Adjust Estimates with CFACSHR #\n",
    "#########################################\n",
    "\n",
    "# Put the estimate on the same per share basis as\n",
    "# company reported EPS using CRSP Adjustment factors. \n",
    "# New_value is the estimate adjusted to be on the \n",
    "# same basis with reported earnings.\n",
    "\n",
    "ibes1 = pd.merge(ibes1, ibes_anndats, how='inner', on=['permno', 'anndats'])\n",
    "ibes1 = ibes1.drop(['anndats','date'], axis=1).rename(columns={'cfacshr':'cfacshr_ann'})\n",
    "\n",
    "ibes1 = pd.merge(ibes1, ibes_anndats, how='inner', left_on=['permno', 'repdats'], right_on=['permno','anndats'])\n",
    "ibes1 = ibes1.drop(['anndats','date'], axis=1).rename(columns={'cfacshr':'cfacshr_rep'})\n",
    "\n",
    "ibes1['new_value'] = (ibes1.cfacshr_rep/ibes1.cfacshr_ann)*ibes1.value\n",
    "\n",
    "# Sanity check: there should be one most recent estimate for \n",
    "# a given firm-fiscal period end combination \n",
    "ibes1 = ibes1.sort_values(by=['ticker','fpedats','estimator','analys']).drop_duplicates()"
   ],
   "id": "9dbed1b3320855a5",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:38:51.459058Z",
     "start_time": "2024-10-11T22:38:51.023315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the median forecast based on estimates in the 90 days prior to the EAD\n",
    "\n",
    "grp_permno = ibes1.groupby(['ticker','fpedats', 'basis','repdats', 'act']).permno.max().reset_index()\n",
    "\n",
    "medest = ibes1.groupby(['ticker','fpedats', 'basis','repdats', 'act']).new_value.agg(['median','count']).reset_index()\n",
    "medest = pd.merge(medest, grp_permno, how='inner', on=['ticker','fpedats','basis', 'repdats', 'act'])\n",
    "medest = medest.rename(columns={'median': 'medest', 'count':'numest'})"
   ],
   "id": "b5a32da430eb1685",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:39:19.783355Z",
     "start_time": "2024-10-11T22:39:00.589970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "######################################\n",
    "# Step 5. Merge with Compustat Data  #\n",
    "######################################\n",
    "\n",
    "# get items from fundq\n",
    "fundq = conn.raw_sql(f\"\"\"\n",
    "                        select gvkey, fyearq, fqtr, conm, datadate, rdq, epsfxq, epspxq, cshoq, prccq, \n",
    "                        ajexq, spiq, cshoq, cshprq, cshfdq, saleq, atq, fyr, datafqtr, cshoq*prccq as mcap  \n",
    "                        from comp.fundq \n",
    "                        where consol='C' and popsrc='D' and indfmt='INDL' and datafmt='STD'\n",
    "                        and datadate between '{crsp_begdate}' and '{crsp_enddate}' \n",
    "                        \"\"\", date_cols = ['datadate', 'datafqtr', 'rdq'])\n",
    "\n",
    "fundq = fundq.loc[((fundq.atq>0) | (fundq.saleq.notna())) & (fundq.datafqtr.notna())]\n",
    "\n",
    "\n",
    "# Calculate link date ranges for givken gvkey and ticker combination\n",
    "\n",
    "gvkey_mindt1 = gvkey.groupby(['gvkey', 'ticker']).linkdt.min().reset_index().rename(columns={'linkdt':'mindate'})\n",
    "gvkey_maxdt1 = gvkey.groupby(['gvkey', 'ticker']).linkenddt.max().reset_index().rename(columns={'linkenddt':'maxdate'})\n",
    "gvkey_dt1 = pd.merge(gvkey_mindt1, gvkey_maxdt1, how='inner', on=['gvkey','ticker'])\n",
    "\n",
    "\n",
    "# Use the date range to merge\n",
    "comp = pd.merge(fundq, gvkey_dt1, how='left', on =['gvkey'])\n",
    "comp = comp.loc[(comp.ticker.notna()) & (comp.datadate<=comp.maxdate) & (comp.datadate>=comp.mindate)]\n",
    "\n",
    "# Merge with the median esitmates\n",
    "comp = pd.merge(comp, medest, how = 'left', left_on=['ticker','datadate'], right_on=['ticker', 'fpedats'])\n",
    "\n",
    "# Sort data and drop duplicates\n",
    "comp = comp.sort_values(by=['gvkey','fqtr','fyearq']).drop_duplicates()"
   ],
   "id": "e371993bbf333ad1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\wrds\\sql.py:579: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in df:\n",
      "D:\\Users\\wangy\\anaconda3\\Lib\\site-packages\\wrds\\sql.py:579: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in df:\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:39:34.722177Z",
     "start_time": "2024-10-11T22:39:33.164983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###########################\n",
    "# Step 6. Calculate SUEs  #\n",
    "###########################\n",
    "\n",
    "# block handling lag eps\n",
    "\n",
    "sue = comp.sort_values(by=['gvkey','fqtr','fyearq'])\n",
    "\n",
    "sue['dif_fyearq'] = sue.groupby(['gvkey', 'fqtr']).fyearq.diff()\n",
    "sue['laggvkey']   = sue.gvkey.shift(1)\n",
    "\n",
    "# handling same qtr previous year\n",
    "\n",
    "cond_year = sue.dif_fyearq==1 # year increment is 1\n",
    "\n",
    "sue['lagadj']     = np.where(cond_year, sue.ajexq.shift(1), None)\n",
    "sue['lageps_p']   = np.where(cond_year, sue.epspxq.shift(1), None)\n",
    "sue['lageps_d']   = np.where(cond_year, sue.epsfxq.shift(1), None)\n",
    "sue['lagshr_p']   = np.where(cond_year, sue.cshprq.shift(1), None)\n",
    "sue['lagshr_d']   = np.where(cond_year, sue.cshfdq.shift(1), None)\n",
    "sue['lagspiq']    = np.where(cond_year, sue.spiq.shift(1), None)\n",
    "\n",
    "# handling first gvkey\n",
    "\n",
    "cond_gvkey = sue.gvkey != sue.laggvkey # first.gvkey\n",
    "\n",
    "sue['lagadj']     = np.where(cond_gvkey, None, sue.lagadj)\n",
    "sue['lageps_p']   = np.where(cond_gvkey, None, sue.lageps_p)\n",
    "sue['lageps_d']   = np.where(cond_gvkey, None, sue.lageps_d)\n",
    "sue['lagshr_p']   = np.where(cond_gvkey, None, sue.lagshr_p)\n",
    "sue['lagshr_d']   = np.where(cond_gvkey, None, sue.lagshr_d)\n",
    "sue['lagspiq']    = np.where(cond_gvkey, None, sue.lagspiq)\n",
    "\n",
    "\n",
    "# handling reporting basis \n",
    "\n",
    "# Basis = P and missing are treated the same\n",
    "\n",
    "sue['actual1'] = np.where(sue.basis=='D', sue.epsfxq/sue.ajexq, sue.epspxq/sue.ajexq)\n",
    "\n",
    "sue['actual2'] = np.where(sue.basis=='D', \\\n",
    "                            (sue.epsfxq.fillna(0)-(0.65*sue.spiq/sue.cshfdq).fillna(0))/sue.ajexq, \\\n",
    "                            (sue.epspxq.fillna(0)-(0.65*sue.spiq/sue.cshprq).fillna(0))/sue.ajexq\n",
    "                           )\n",
    "\n",
    "sue['expected1'] = np.where(sue.basis=='D', sue.lageps_d/sue.lagadj, sue.lageps_p/sue.lagadj)\n",
    "sue['expected2'] = np.where(sue.basis=='D', \\\n",
    "                              (sue.lageps_d.fillna(0)-(0.65*sue.lagspiq/sue.lagshr_d).fillna(0))/sue.lagadj, \\\n",
    "                              (sue.lageps_p.fillna(0)-(0.65*sue.lagspiq/sue.lagshr_p).fillna(0))/sue.lagadj\n",
    "                             )\n",
    "\n",
    "# SUE calculations\n",
    "sue['sue1'] = (sue.actual1 - sue.expected1) / (sue.prccq/sue.ajexq)\n",
    "sue['sue2'] = (sue.actual2 - sue.expected2) / (sue.prccq/sue.ajexq)\n",
    "sue['sue3'] = (sue.act - sue.medest) / sue.prccq\n",
    "\n",
    "sue = sue[['ticker','permno','gvkey','conm','fyearq','fqtr','fyr','datadate','repdats','rdq', \\\n",
    "           'sue1','sue2','sue3','basis','act','medest','numest','prccq','mcap']]\n",
    "\n",
    "# Shifting the announcement date to be the next trading day\n",
    "# Defining the day after the following quarterly EA as leadrdq1\n",
    "\n",
    "# unique rdq \n",
    "uniq_rdq = comp[['rdq']].drop_duplicates()\n",
    "\n",
    "# Create up to 5 days post rdq relative to rdq\n",
    "for i in range(0, 5):\n",
    "    uniq_rdq[i] = uniq_rdq.rdq + datetime.timedelta(days=i)\n",
    "\n",
    "# reshape (transpose) for later join with crsp trading dates\n",
    "expand_rdq = uniq_rdq.set_index('rdq').stack().reset_index().\\\n",
    "rename(columns={'level_1':'post', 0:'post_date'})\n",
    "\n",
    "# merge with crsp trading dates\n",
    "eads1 = pd.merge(expand_rdq, crsp_dats, how='left', left_on=['post_date'], right_on=['date'])\n",
    "\n",
    "# create the dgap (days gap) variable for min selection\n",
    "eads1['dgap'] = eads1.date-eads1.rdq\n",
    "\n",
    "# LOC deprecated, use reindex instead\n",
    "#eads1 = eads1.loc[eads1.groupby('rdq')['dgap'].idxmin()].rename(columns={'date':'rdq1'})\n",
    "eads1 = eads1.reindex(eads1.groupby('rdq')['dgap'].idxmin()).rename(columns={'date':'rdq1'})\n",
    "\n",
    "# create sue_final\n",
    "sue_final = pd.merge(sue, eads1[['rdq','rdq1']], how='left', on=['rdq'])\n",
    "sue_final = sue_final.sort_values(by=['gvkey', 'fyearq','fqtr'], ascending=[True, False, False]).drop_duplicates()"
   ],
   "id": "51947730d6ee22ac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangy\\AppData\\Local\\Temp\\ipykernel_26396\\877030561.py:48: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  (sue.lageps_d.fillna(0)-(0.65*sue.lagspiq/sue.lagshr_d).fillna(0))/sue.lagadj, \\\n",
      "C:\\Users\\wangy\\AppData\\Local\\Temp\\ipykernel_26396\\877030561.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  (sue.lageps_p.fillna(0)-(0.65*sue.lagspiq/sue.lagshr_p).fillna(0))/sue.lagadj\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:41:54.804688Z",
     "start_time": "2024-10-11T22:41:54.601536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Filter from Livnat & Mendenhall (2006):                                \n",
    "#- earnings announcement date is reported in Compustat                   \n",
    "#- the price per share is available from Compustat at fiscal quarter end  \n",
    "#- price is greater than $1                                              \n",
    "#- the market (book) equity at fiscal quarter end is available and is    \n",
    "# EADs in Compustat and in IBES (if available)should not differ by more  \n",
    "# than one calendar day larger than $5 mil.                              \n",
    "\n",
    "sue_final['leadrdq1'] = sue_final.rdq1.shift(1) # next consecutive EAD\n",
    "sue_final['leadgvkey'] = sue_final.gvkey.shift(1)\n",
    "\n",
    "# If first gvkey then leadrdq1 = rdq1+3 months\n",
    "# Else leadrdq1 = previous rdq1\n",
    "\n",
    "sue_final['leadrdq1'] = np.where(sue_final.gvkey == sue_final.leadgvkey, \n",
    "                                  sue_final.rdq1.shift(1), \n",
    "                                  sue_final.rdq1 + pd.DateOffset(months=3))\n",
    "\n",
    "\n",
    "#sue_final['dgap'] = (sue_final.repdats - sue_final.rdq).fillna(0)\n",
    "sue_final['dgap'] = (sue_final.repdats - sue_final.rdq).fillna(pd.Timedelta(days=0))\n",
    "sue_final = sue_final.loc[(sue_final.rdq1 != sue_final.leadrdq1)]\n",
    "\n",
    "# Various conditioning for filtering\n",
    "cond1 = (sue_final.sue1.notna()) & (sue_final.sue2.notna()) & (sue_final.repdats.isna())\n",
    "cond2 = (sue_final.repdats.notna()) & (sue_final.dgap<=datetime.timedelta(days=1)) & (sue_final.dgap>=datetime.timedelta(days=-1))\n",
    "sue_final = sue_final.loc[cond1 | cond2]\n",
    "\n",
    "# Impose restriction on price and marketcap\n",
    "sue_final = sue_final.loc[(sue_final.rdq.notna()) & (sue_final.prccq>1) & (sue_final.mcap>5)]\n",
    "\n",
    "# Keep relevant columns\n",
    "sue_final = sue_final[['gvkey', 'ticker','permno','conm', 'dgap',\\\n",
    "                       'fyearq','fqtr','datadate','fyr','rdq','rdq1','leadrdq1','repdats',\\\n",
    "                       'mcap','medest','act','numest','basis','sue1','sue2','sue3']]"
   ],
   "id": "9e4e6938eee615e1",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T23:06:04.467877Z",
     "start_time": "2024-10-11T23:06:04.236643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key in ['sue1','sue2','sue3']:\n",
    "    sue_final[key] = pd.to_numeric(sue_final[key], errors='coerce')\n",
    "    \n",
    "sue_final.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "sue_final.describe()"
   ],
   "id": "47f5d8b8d66f6288",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              permno                         dgap         fyearq  \\\n",
       "count  130765.000000                       200706  200706.000000   \n",
       "mean    66999.979842  -1 days +23:57:57.313084811    2011.900870   \n",
       "min     10001.000000            -1 days +00:00:00    2006.000000   \n",
       "25%     45356.000000              0 days 00:00:00    2009.000000   \n",
       "50%     81577.000000              0 days 00:00:00    2012.000000   \n",
       "75%     89606.000000              0 days 00:00:00    2015.000000   \n",
       "max     93436.000000              1 days 00:00:00    2018.000000   \n",
       "std     29569.893916    0 days 02:54:07.412816348       3.196472   \n",
       "\n",
       "                fqtr                       datadate            fyr  \\\n",
       "count  200706.000000                         200706  200706.000000   \n",
       "mean        2.498635  2012-06-30 12:16:16.329556736      10.540921   \n",
       "min         1.000000            2006-09-30 00:00:00       1.000000   \n",
       "25%         2.000000            2009-09-30 00:00:00      12.000000   \n",
       "50%         2.000000            2012-06-30 00:00:00      12.000000   \n",
       "75%         3.000000            2015-03-31 00:00:00      12.000000   \n",
       "max         4.000000            2017-12-31 00:00:00      12.000000   \n",
       "std         1.116341                            NaN       3.027908   \n",
       "\n",
       "                                 rdq                           rdq1  \\\n",
       "count                         200706                         200706   \n",
       "mean   2012-08-07 03:16:20.526740736  2012-08-07 03:24:20.512391168   \n",
       "min              2006-10-26 00:00:00            2006-10-26 00:00:00   \n",
       "25%              2009-10-28 00:00:00            2009-10-28 00:00:00   \n",
       "50%              2012-07-31 00:00:00            2012-07-31 00:00:00   \n",
       "75%              2015-05-06 00:00:00            2015-05-06 00:00:00   \n",
       "max              2019-05-16 00:00:00            2019-05-16 00:00:00   \n",
       "std                              NaN                            NaN   \n",
       "\n",
       "                            leadrdq1                        repdats  \\\n",
       "count                         200475                         130765   \n",
       "mean   2012-11-07 17:08:01.346801664  2012-03-03 09:14:15.063663872   \n",
       "min              2007-02-12 00:00:00            2007-02-06 00:00:00   \n",
       "25%              2010-02-04 00:00:00            2009-08-04 00:00:00   \n",
       "50%              2012-10-31 00:00:00            2012-02-28 00:00:00   \n",
       "75%              2015-08-05 00:00:00            2014-10-15 00:00:00   \n",
       "max              2019-08-16 00:00:00            2017-09-14 00:00:00   \n",
       "std                              NaN                            NaN   \n",
       "\n",
       "                mcap         medest            act         numest  \\\n",
       "count  200706.000000  130628.000000  130765.000000  130765.000000   \n",
       "mean     5747.848596       0.463624       0.468963       6.006202   \n",
       "min         5.001850     -33.995241     -64.050000       0.000000   \n",
       "25%       154.532872       0.030000       0.030000       2.000000   \n",
       "50%       642.287755       0.240000       0.250000       4.000000   \n",
       "75%      2752.029360       0.540000       0.570000       8.000000   \n",
       "max    859967.798730    1631.000000    1655.000000      48.000000   \n",
       "std     22264.951956      12.743514      12.811793       5.631966   \n",
       "\n",
       "                sue1           sue2           sue3  \n",
       "count  193676.000000  193885.000000  130628.000000  \n",
       "mean        0.373510       0.375688      -0.002782  \n",
       "min      -268.341085    -182.070555     -14.471074  \n",
       "25%        -0.007732      -0.006814      -0.001335  \n",
       "50%         0.000765       0.000832       0.000484  \n",
       "75%         0.007555       0.006811       0.002666  \n",
       "max     23035.059621   23066.339391      16.205565  \n",
       "std        81.165426      81.509937       0.129003  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>dgap</th>\n",
       "      <th>fyearq</th>\n",
       "      <th>fqtr</th>\n",
       "      <th>datadate</th>\n",
       "      <th>fyr</th>\n",
       "      <th>rdq</th>\n",
       "      <th>rdq1</th>\n",
       "      <th>leadrdq1</th>\n",
       "      <th>repdats</th>\n",
       "      <th>mcap</th>\n",
       "      <th>medest</th>\n",
       "      <th>act</th>\n",
       "      <th>numest</th>\n",
       "      <th>sue1</th>\n",
       "      <th>sue2</th>\n",
       "      <th>sue3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>130765.000000</td>\n",
       "      <td>200706</td>\n",
       "      <td>200706.000000</td>\n",
       "      <td>200706.000000</td>\n",
       "      <td>200706</td>\n",
       "      <td>200706.000000</td>\n",
       "      <td>200706</td>\n",
       "      <td>200706</td>\n",
       "      <td>200475</td>\n",
       "      <td>130765</td>\n",
       "      <td>200706.000000</td>\n",
       "      <td>130628.000000</td>\n",
       "      <td>130765.000000</td>\n",
       "      <td>130765.000000</td>\n",
       "      <td>193676.000000</td>\n",
       "      <td>193885.000000</td>\n",
       "      <td>130628.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66999.979842</td>\n",
       "      <td>-1 days +23:57:57.313084811</td>\n",
       "      <td>2011.900870</td>\n",
       "      <td>2.498635</td>\n",
       "      <td>2012-06-30 12:16:16.329556736</td>\n",
       "      <td>10.540921</td>\n",
       "      <td>2012-08-07 03:16:20.526740736</td>\n",
       "      <td>2012-08-07 03:24:20.512391168</td>\n",
       "      <td>2012-11-07 17:08:01.346801664</td>\n",
       "      <td>2012-03-03 09:14:15.063663872</td>\n",
       "      <td>5747.848596</td>\n",
       "      <td>0.463624</td>\n",
       "      <td>0.468963</td>\n",
       "      <td>6.006202</td>\n",
       "      <td>0.373510</td>\n",
       "      <td>0.375688</td>\n",
       "      <td>-0.002782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>-1 days +00:00:00</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006-09-30 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006-10-26 00:00:00</td>\n",
       "      <td>2006-10-26 00:00:00</td>\n",
       "      <td>2007-02-12 00:00:00</td>\n",
       "      <td>2007-02-06 00:00:00</td>\n",
       "      <td>5.001850</td>\n",
       "      <td>-33.995241</td>\n",
       "      <td>-64.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-268.341085</td>\n",
       "      <td>-182.070555</td>\n",
       "      <td>-14.471074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45356.000000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2009-09-30 00:00:00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2009-10-28 00:00:00</td>\n",
       "      <td>2009-10-28 00:00:00</td>\n",
       "      <td>2010-02-04 00:00:00</td>\n",
       "      <td>2009-08-04 00:00:00</td>\n",
       "      <td>154.532872</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.007732</td>\n",
       "      <td>-0.006814</td>\n",
       "      <td>-0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>81577.000000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2012-06-30 00:00:00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2012-07-31 00:00:00</td>\n",
       "      <td>2012-07-31 00:00:00</td>\n",
       "      <td>2012-10-31 00:00:00</td>\n",
       "      <td>2012-02-28 00:00:00</td>\n",
       "      <td>642.287755</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>89606.000000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2015-03-31 00:00:00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2015-05-06 00:00:00</td>\n",
       "      <td>2015-05-06 00:00:00</td>\n",
       "      <td>2015-08-05 00:00:00</td>\n",
       "      <td>2014-10-15 00:00:00</td>\n",
       "      <td>2752.029360</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.006811</td>\n",
       "      <td>0.002666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93436.000000</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2017-12-31 00:00:00</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2019-05-16 00:00:00</td>\n",
       "      <td>2019-05-16 00:00:00</td>\n",
       "      <td>2019-08-16 00:00:00</td>\n",
       "      <td>2017-09-14 00:00:00</td>\n",
       "      <td>859967.798730</td>\n",
       "      <td>1631.000000</td>\n",
       "      <td>1655.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>23035.059621</td>\n",
       "      <td>23066.339391</td>\n",
       "      <td>16.205565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29569.893916</td>\n",
       "      <td>0 days 02:54:07.412816348</td>\n",
       "      <td>3.196472</td>\n",
       "      <td>1.116341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.027908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22264.951956</td>\n",
       "      <td>12.743514</td>\n",
       "      <td>12.811793</td>\n",
       "      <td>5.631966</td>\n",
       "      <td>81.165426</td>\n",
       "      <td>81.509937</td>\n",
       "      <td>0.129003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T23:10:12.241839Z",
     "start_time": "2024-10-11T23:10:12.168999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sue_final.dropna(subset=['sue1', 'sue2', 'sue3'], how='all', inplace=True)\n",
    "sue_final.drop_duplicates(subset=['gvkey', 'fyearq', 'fqtr'], keep='first', inplace=True)"
   ],
   "id": "c6df3a9164c9ad9b",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T23:10:35.410600Z",
     "start_time": "2024-10-11T23:10:35.300618Z"
    }
   },
   "cell_type": "code",
   "source": "sue_final.to_pickle(os.path.join(const.TEMP_PATH, '20241012_sue_final.pkl'))",
   "id": "5933230054843605",
   "outputs": [],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
